{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of Projects undertaken while studying Data Science :\n",
    "\n",
    "* Indian Data Set : A few visualizations using Tableau for some data sets I found interesting to look into. (Data from data.gov.in)\n",
    "\n",
    "* Kaggle : A script used in Kaggle competition for the Analytics Edge course at edX by MITx. The aim was to predict the voting category for the given test set using a training set.\n",
    "\n",
    "* Panama Papers : A visualization in R of Indian addresses mentioned in the latest Panama Papers data set. The necessary data was filtered in R and the script used is also included. It is also accompanied by 2 more visualizations created with the help of BatchGeo and Google's Fusion Tables, source for which is the accompanying CSV file.\n",
    "\n",
    "* TextNook Assignment : 2 Assignments part of an Interview. One involves scraping data from a blog. The other was to create a Reddit Clone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indian Data Set :\n",
    "\n",
    "* 3 data sets taken from data.gov.in have been visualized using Tableau\n",
    "* First visualization is regarding average number of minutes advertisements are shown on TV channels during peak hours.\n",
    "* Second one relates to Crime data over the years and their categorical breakdowns in Indian states.\n",
    "* Third is showing the growth of subscribers in DTH space among various players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle : \n",
    "* This was part of the course 'Analytics Edge' on edX. Here we had to predict the voting outcomes in the test set based on survey results and demographic data.\n",
    "* It involved cleaning data and treating the missing values.\n",
    "* Missing values for demographic data were imputed using MICE package\n",
    "* Various models were used to predict the outcome.\n",
    "* Independent variables were chosen with the help of importance via the basic LogModel. Along with the few other questions were added by throughly understanding the Questions data given to us. Some variables were dropped as well.\n",
    "* Generated files are included in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panama Papers :\n",
    "* A visualization of Indian Addresse mentioned in the Panama Papers.\n",
    "* The main database was filtered and characters like '-' or '*' were removed from the address so as to facilitate easier search\n",
    "* The data was then fed to a script (which is included) which geo-coded the addresses. The script also generated a basic visualization in R.\n",
    "* The final geocoded addresses are saved in a csv file\n",
    "* The csv files were then used in BatchGeo and Google FusionTables to create a more interactive visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextNook Assignment : \n",
    "\n",
    "* A blog was scraped as part of the assignment given by TextNook\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
